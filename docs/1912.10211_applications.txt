PRACTICAL APPLICATIONS FOUND IN PSYCHOACOUSTICS RESEARCH PAPER:
============================================================

PAGE 2 - Applications: example
Content: 1
PANNs: Large-Scale Pretrained Audio Neural Networks for
Audio Pattern Recognition
Qiuqiang Kong, Student Member, IEEE, Yin Cao, Member, IEEE, Turab Iqbal,
Yuxuan Wang, Wenwu Wang, Senior Member, IEEE and Mark D. Plumbley, Fellow, IEEE
Abstract‚ÄîAudio pattern recognition is an important research Markov model (HMM) to classify three types of sounds:
topic in the machine learning area, and includes several tasks wooden door open and shut, metal dropped and water poured.
such as audio tagging, acou
--------------------------------------------------

PAGE 3 - Applications: experiment, results
Content: 2
tasks. However, previous works on transfer learning mainly TABLEI
used music datasets or were limited to smaller datasets than CNNSFORAUDIOSETTAGGING
AudioSet. In this work, we investigate transferring PANNs
VGGish[1] CNN6 CNN10 CNN14
to a wide range of audio pattern recognition tasks, including Log-melspectrogram Log-melspectrogram
96frames√ó64melbins 1000frames√ó64melbins
acoustic scene classification, general audio tagging, music 3√ó3@64 5√ó5@64 (cid:18)3√ó3@64(cid:19) (cid:18)3√ó3@64(cid:19)
√ó2 
--------------------------------------------------

PAGE 4 - Applications: example
Content: 3
TABLEII TABLEIII
RESNETSFORAUDIOSETTAGGING MOBILENETSFORAUDIOSETTAGGING
ResNet22 ResNet38 ResNet54 MobileNetV1 MobileNetV2
Logmelspectrogram1000frames√ó64melbins 3√ó3@32,BN,ReLU
(cid:0)3√ó3@512,BN,ReLU (cid:1)
√ó2 Pooling2√ó2
Pooling2√ó2 V1Block@64 V2Block,t=1@16
(cid:0) BasicB@64(cid:1)
√ó2
(cid:0) BasicB@64(cid:1)
√ó3
(cid:0) BottleneckB@64(cid:1)
√ó3 V1Block@128 (V2Block,t=6@24)√ó2
Pooling2√ó2 Pooling2√ó2
(cid:0) BasicB@128(cid:1)
√ó2
(cid:0) BasicB@128(cid:1)
√ó4
(cid:0) BottleneckB@128(cid:1)
√ó4 V1Bloc
--------------------------------------------------

PAGE 5 - Applications: application, example, experiment
Content: 4
high level features. In [33] an 18-layer DaiNet with four Prediction
convolutional layers in each convolutional block had achieved
the best classification performance on the UrbanSound8K
2D CNN
dataset. layers
2) LeeNet: Different from the DaiNet that applied large
kernels in the first layer, LeeNet [44] applied small kernels
Concat
with a length of 3 on the waveforms. LeeNet stacked the
kernels with lengths of 3 to replace the fixed length windows
forSTFT.LeeNetiscomposedofseveralconvolutiona
--------------------------------------------------

PAGE 6 - Applications: example
Content: 5
IV. DATAPROCESSING
(a) (ùë•(cid:2868),ùë¶(cid:2868))‚ààùê∑(cid:2885)(cid:2931)(cid:2914)(cid:2919)(cid:2925)(cid:2903)(cid:2915)(cid:2930) ùë•(cid:2868) NN Embedding FC
AudioSet
ùë¶(cid:2868)
In this section, we introduce data processing for AudioSet
tagging,includingdatabalancinganddataaugmentation.Data Copy parameters
balancing is a technique to solve the training problem of (b) (ùë•(cid:2869),ùë¶(cid:2869))‚ààùê∑(cid:2898)(cid:2915)(cid:2933)(cid:2904)(cid:2911)(cid:2929)(cid:2921) ùë•(cid:2869) NN Embedding FC

--------------------------------------------------

PAGE 7 - Applications: experiment, evaluation, results
Content: 6
1.0
0.8
0.6
0.4
0.2
0.0
0 200k 400k 600k
Iterations
PA
1.0
Music (937,780)
Speech (937,432)
V M e u h s ic ic le a l ( 1 (1 2 1 2 2 ,2 ,3 3 3 1 7 ) ) 0.8
Inside, small (70,159)
Guitar (49,200)
Plucked string (42,509) 0.6
Car (39,503)
Singing (39,469)
Animal (37,857) 0.4
0.2
0.0
0 200k 400k 600k
Iterations
PA
1.0
Canidae, dogs, (1,592)
Traditional (1,579)
T S a a b d l a m ( u 1 s , i 5 c 7 ( 5 1 ) ,572) 0.8
Ska (1,563)
Chant (1,559)
Scary music (1,539) 0.6
Liquid (1,533)
Traffic noise, (1,523)
--------------------------------------------------

PAGE 8 - Applications: application, example, experiment, results
Content: 7
TABLEV TABLEVII
RESULTSOFDIFFERENTHOPSIZES RESULTSOFAUDIOSETTAGGINGSYSTEMS
Hopsize Timeresolution mAP AUC d-prime mAP AUC d-prime
1000 31.25ms 0.400 0.969 2.645 CNN6 0.343 0.965 2.568
640 20.00ms 0.417 0.972 2.711 CNN10 0.380 0.971 2.678
500 15.63ms 0.417 0.971 2.682 CNN14 0.431 0.973 2.732
320 10.00ms 0.431 0.973 2.732
ResNet22 0.430 0.973 0.270
ResNet38 0.434 0.974 2.737
ResNet54 0.429 0.971 2.675
TABLEVI
RESULTSOFDIFFERENTEMBEDDINGDIMENSIONS MobileNetV1 0.389 0.970 2.653
MobileNetV2 0.383 0
--------------------------------------------------

PAGE 9 - Applications: experiment
Content: 8
TABLEVIII
NUMBEROFMULTI-ADDSANDPARAMETERSOFDIFFERENTSYSTEMS
Multi-Adds Parameters
CNN6 21.986G 4,837,455
CNN10 21.986G 4,837,455
CNN14 42.220G 80,753,615
ResNet22 30.081G 63,675,087
ResNet38 48.962G 73,783,247
ResNet54 54.563G 104,318,159
MobileNetV1 3.614G 4,796,303
MobileNetV2 2.810G 4,075,343
DaiNet 30.395G 4,385,807
LeeNet 4.741G 748,367
LeeNet24 26.369G 10,003,791
Res1dNet31 32.688G 80,464,463
Res1dNet51 61.833G 106,538,063
Wavegram-CNN 44.234G 80,991,759
Wavegram-Logmel-CNN 53.510G 81,06
--------------------------------------------------

PAGE 10 - Applications: results
Content: 9
1.0
0.8
0.6
0.4
0.2
0.0
2 5 10 20 32 (all)
Training samples per class
ycaruccA
1.0
0.8
0.6
Finetune 0.4
Scratch
Freeze + 1layer 0.2
Freeze + 3 layers
0.0
2 5 10 20 50 100 200 500 ~918 (all)
Training samples per class
Fig. 5. Accuracy of ESC-50 with various number of training samples per
class.
TABLEIX
ACCURACYOFESC-50
STOA[48] Scratch fine-tune Freeze_L1 Freeze_L3
Acc. 0.865 0.833 0.947 0.908 0.918
dataset with 40 samples per class. Table IX shows the 5-
fold cross validation [49] accuracy of 
--------------------------------------------------

PAGE 11 - Applications: example, evaluation
Content: 10
1.0
0.8
0.6
0.4
0.2
0.0
2 5 10 20 50 100 200 300 (all)
Training samples per class
ycaruccA
1.0
0.8
0.6
Finetune 0.4
Scratch
Freeze + 1layer 0.2
Freeze + 3 layers
0.0
2 5 10 20 50 100 (all)
Training samples per class
Fig.8. AccuracyofMSoSwithvariousnumberoftrainingsamplesperclass.
TABLEXII
ACCURACYOFMSOS
STOA[52] Scratch Fine-tune Freeze_L1 Freeze_L3
Acc. 0.930 0.760 0.960 0.886 0.930
five categories: ‚ÄúNature‚Äù, ‚ÄúMusic‚Äù, ‚ÄúHuman‚Äù, ‚ÄúEffects‚Äù and
‚ÄúUrban‚Äù. The dataset consists of a development set 
--------------------------------------------------

PAGE 12 - Applications: application, experiment, conclusion
Content: 11
the performance much. Our adapted one-dimensional system [5] S. J. Lim, S. J. Jang, J. Y. Lim, and J. H. Ko, ‚ÄúClassification of
Res1dNet31 achieves an mAP of 0.365, outperforming the snoring sound based on a recurrent neural network,‚Äù Expert Systems
withApplications,vol.123,pp.237‚Äì245,2019.
DaiNet [33] of 0.295 and LeeNet11 [44] of 0.266. Our
[6] J.P.Woodard,‚ÄúModelingandclassificationofnaturalsoundsbyproduct
proposed Wavegram-CNN achieves the highest mAP of 0.389 codehiddenMarkovmodels,‚ÄùIEEET
--------------------------------------------------

PAGE 14 - Applications: application
Content: 13
and H. Hamme, ‚ÄúAn MFCC-GMM approach for event detection and https://cvssp.org/projects/making_sense_of_sounds/site/assets/
classification,‚ÄùinIEEEWorkshoponApplicationsofSignalProcessing challenge_abstracts_and_figures/Tianxiang_Chen.pdf,2018.
toAudioandAcoustics(WASPAA),2013,pp.1‚Äì3. [53] E.Fonseca,M.Plakal,F.Font,D.P.W.Ellis,X.Favory,J.Pons,and
[30] A. Mesaros, T. Heittola, A. Eronen, and T. Virtanen, ‚ÄúAcoustic event X.Serra,‚ÄúGeneral-purposetaggingoffreesoundaudiowithaudiosetla-
detection in 
--------------------------------------------------

